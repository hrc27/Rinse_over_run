{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "import feather\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0cec3a87cf5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglorot_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_limited represents a subset of the entire training set, sampled to reflect the distribution of phases found in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_path = 'train_limited.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limited = feather.read_dataframe(limited_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_labels contains the final turbidity for each unique process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = 'train_labels.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = feather.read_dataframe(label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect each process into a single sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad entries so they are uniform in length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in essence we want a three-dimension matrix of shape (m, T, f) - where m is the number of unique processes, T is the number of time-sequences, and f is the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do that, I think I'll need to group the data by the process_id, and then somehow split each group into it's own 2-dimensional matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_cols are the columns that seemed most valuable to keep (based on the Benchmark Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cols = [\n",
    "    'timestamp',\n",
    "    'process_id',\n",
    "    'pipeline',\n",
    "    'phase',\n",
    "    'object_id',\n",
    "    'supply_flow',\n",
    "    'supply_pressure',\n",
    "    'return_temperature',\n",
    "    'return_conductivity',\n",
    "    'return_turbidity',\n",
    "    'return_flow',\n",
    "    'tank_level_pre_rinse',\n",
    "    'tank_level_caustic',\n",
    "    'tank_level_acid',\n",
    "    'tank_level_clean_water',\n",
    "    'tank_temperature_pre_rinse',\n",
    "    'tank_temperature_caustic',\n",
    "    'tank_temperature_acid',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_converted just converts any non-numeric values into numbers (which is basically just the pipeline number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_converted = pd.get_dummies(train_limited[ts_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_converted.process_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate matrices by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: Create m different matrices of size (? x f) by looping over the process_id and separating them into different tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Figure out the dimensions of each process_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we know each process has a set number of features (columns), but they vary by number of rows (a.k.a. number of timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Get a list of all the process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train_converted.process_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4902\n"
     ]
    }
   ],
   "source": [
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Inspect some example process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_0 = train_converted[train_converted.process_id == ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>process_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>supply_flow</th>\n",
       "      <th>supply_pressure</th>\n",
       "      <th>return_temperature</th>\n",
       "      <th>return_conductivity</th>\n",
       "      <th>return_turbidity</th>\n",
       "      <th>return_flow</th>\n",
       "      <th>tank_level_pre_rinse</th>\n",
       "      <th>tank_level_caustic</th>\n",
       "      <th>tank_level_acid</th>\n",
       "      <th>tank_level_clean_water</th>\n",
       "      <th>tank_temperature_pre_rinse</th>\n",
       "      <th>tank_temperature_caustic</th>\n",
       "      <th>tank_temperature_acid</th>\n",
       "      <th>pipeline_L1</th>\n",
       "      <th>pipeline_L10</th>\n",
       "      <th>pipeline_L11</th>\n",
       "      <th>pipeline_L12</th>\n",
       "      <th>pipeline_L2</th>\n",
       "      <th>pipeline_L3</th>\n",
       "      <th>pipeline_L4</th>\n",
       "      <th>pipeline_L6</th>\n",
       "      <th>pipeline_L7</th>\n",
       "      <th>pipeline_L8</th>\n",
       "      <th>pipeline_L9</th>\n",
       "      <th>phase_acid</th>\n",
       "      <th>phase_caustic</th>\n",
       "      <th>phase_intermediate_rinse</th>\n",
       "      <th>phase_pre_rinse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-15 04:20:47</td>\n",
       "      <td>20001</td>\n",
       "      <td>405</td>\n",
       "      <td>8550.348</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>18.044704</td>\n",
       "      <td>4.990765</td>\n",
       "      <td>0.177228</td>\n",
       "      <td>15776.9100</td>\n",
       "      <td>55.499672</td>\n",
       "      <td>41.555992</td>\n",
       "      <td>44.026875</td>\n",
       "      <td>49.474102</td>\n",
       "      <td>32.385708</td>\n",
       "      <td>83.036750</td>\n",
       "      <td>73.03241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-15 04:20:49</td>\n",
       "      <td>20001</td>\n",
       "      <td>405</td>\n",
       "      <td>11364.294</td>\n",
       "      <td>0.654297</td>\n",
       "      <td>18.229168</td>\n",
       "      <td>3.749680</td>\n",
       "      <td>0.122975</td>\n",
       "      <td>13241.4640</td>\n",
       "      <td>55.487920</td>\n",
       "      <td>41.624170</td>\n",
       "      <td>44.045685</td>\n",
       "      <td>49.457645</td>\n",
       "      <td>32.385708</td>\n",
       "      <td>83.015045</td>\n",
       "      <td>73.03241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-15 04:20:51</td>\n",
       "      <td>20001</td>\n",
       "      <td>405</td>\n",
       "      <td>12174.479</td>\n",
       "      <td>0.699870</td>\n",
       "      <td>18.395544</td>\n",
       "      <td>2.783954</td>\n",
       "      <td>0.387008</td>\n",
       "      <td>10698.7850</td>\n",
       "      <td>55.476166</td>\n",
       "      <td>41.638275</td>\n",
       "      <td>44.045685</td>\n",
       "      <td>49.462350</td>\n",
       "      <td>32.385708</td>\n",
       "      <td>83.015045</td>\n",
       "      <td>73.03241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-15 04:20:53</td>\n",
       "      <td>20001</td>\n",
       "      <td>405</td>\n",
       "      <td>13436.776</td>\n",
       "      <td>0.761502</td>\n",
       "      <td>18.583622</td>\n",
       "      <td>1.769353</td>\n",
       "      <td>0.213397</td>\n",
       "      <td>8007.8125</td>\n",
       "      <td>55.471466</td>\n",
       "      <td>41.647675</td>\n",
       "      <td>44.048030</td>\n",
       "      <td>49.462350</td>\n",
       "      <td>32.385708</td>\n",
       "      <td>83.036750</td>\n",
       "      <td>73.03241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-15 04:20:55</td>\n",
       "      <td>20001</td>\n",
       "      <td>405</td>\n",
       "      <td>13776.766</td>\n",
       "      <td>0.837240</td>\n",
       "      <td>18.627026</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.148293</td>\n",
       "      <td>6004.0510</td>\n",
       "      <td>55.459705</td>\n",
       "      <td>41.654730</td>\n",
       "      <td>44.048030</td>\n",
       "      <td>49.462350</td>\n",
       "      <td>32.385708</td>\n",
       "      <td>83.015045</td>\n",
       "      <td>73.03241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  process_id  object_id  supply_flow  supply_pressure  \\\n",
       "0 2018-04-15 04:20:47       20001        405     8550.348         0.615451   \n",
       "1 2018-04-15 04:20:49       20001        405    11364.294         0.654297   \n",
       "2 2018-04-15 04:20:51       20001        405    12174.479         0.699870   \n",
       "3 2018-04-15 04:20:53       20001        405    13436.776         0.761502   \n",
       "4 2018-04-15 04:20:55       20001        405    13776.766         0.837240   \n",
       "\n",
       "   return_temperature  return_conductivity  return_turbidity  return_flow  \\\n",
       "0           18.044704             4.990765          0.177228   15776.9100   \n",
       "1           18.229168             3.749680          0.122975   13241.4640   \n",
       "2           18.395544             2.783954          0.387008   10698.7850   \n",
       "3           18.583622             1.769353          0.213397    8007.8125   \n",
       "4           18.627026             0.904020          0.148293    6004.0510   \n",
       "\n",
       "   tank_level_pre_rinse  tank_level_caustic  tank_level_acid  \\\n",
       "0             55.499672           41.555992        44.026875   \n",
       "1             55.487920           41.624170        44.045685   \n",
       "2             55.476166           41.638275        44.045685   \n",
       "3             55.471466           41.647675        44.048030   \n",
       "4             55.459705           41.654730        44.048030   \n",
       "\n",
       "   tank_level_clean_water  tank_temperature_pre_rinse  \\\n",
       "0               49.474102                   32.385708   \n",
       "1               49.457645                   32.385708   \n",
       "2               49.462350                   32.385708   \n",
       "3               49.462350                   32.385708   \n",
       "4               49.462350                   32.385708   \n",
       "\n",
       "   tank_temperature_caustic  tank_temperature_acid  pipeline_L1  pipeline_L10  \\\n",
       "0                 83.036750               73.03241            0             0   \n",
       "1                 83.015045               73.03241            0             0   \n",
       "2                 83.015045               73.03241            0             0   \n",
       "3                 83.036750               73.03241            0             0   \n",
       "4                 83.015045               73.03241            0             0   \n",
       "\n",
       "   pipeline_L11  pipeline_L12  pipeline_L2  pipeline_L3  pipeline_L4  \\\n",
       "0             0             0            0            0            1   \n",
       "1             0             0            0            0            1   \n",
       "2             0             0            0            0            1   \n",
       "3             0             0            0            0            1   \n",
       "4             0             0            0            0            1   \n",
       "\n",
       "   pipeline_L6  pipeline_L7  pipeline_L8  pipeline_L9  phase_acid  \\\n",
       "0            0            0            0            0           0   \n",
       "1            0            0            0            0           0   \n",
       "2            0            0            0            0           0   \n",
       "3            0            0            0            0           0   \n",
       "4            0            0            0            0           0   \n",
       "\n",
       "   phase_caustic  phase_intermediate_rinse  phase_pre_rinse  \n",
       "0              0                         0                1  \n",
       "1              0                         0                1  \n",
       "2              0                         0                1  \n",
       "3              0                         0                1  \n",
       "4              0                         0                1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_1 = train_converted[train_converted.process_id == ids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_1.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: They have the same number of columns (31), but the number of rows varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Get the row-counts for all the process_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in ids:\n",
    "    process = train_converted[train_converted.process_id == i]\n",
    "    rows.append(process.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we have a list of all the row-counts  \n",
    "Let's double check the dimensions of the list (it should have 4902 entries, the number of distinct process_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4902"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the row-counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize these lengths, get a sense for how they're distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f87f56dec18>,\n",
       "  <matplotlib.lines.Line2D at 0x7f87f56def60>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f87f56deeb8>,\n",
       "  <matplotlib.lines.Line2D at 0x7f87f56f3630>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f87f56de518>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f87f56f3978>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f87f56f3cc0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so, median somewhere around a 1000, deep right-skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11607"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max is 11607, which means each process_id needs to be 11607 rows longs... that's a lot of padding. Let's save that to a global variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out ways to add zeros to the end of an array - part of Rinse_over_Run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function adds a row to each channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rows(array, row):\n",
    "    # create a new array in which the updated channels will be added \n",
    "    new_array = np.zeros((array.shape[0], array.shape[1]+1, array.shape[2]))\n",
    "    \n",
    "    # loop over every channel in the previous array\n",
    "    for i in range(len(array)):\n",
    "        # check the size of the arrays - new array should have one additional row compared to the array\n",
    "        print(\"new array shape is {}\".format(new_array[i].shape))\n",
    "        print(\"old array shape is {}\".format(array[i].shape))\n",
    "        \n",
    "        # the row length should match the number of array columns\n",
    "        print(\"row shape is {}\".format(row.shape))\n",
    "        \n",
    "        # create a new array which has the row appended to it\n",
    "        appended = np.append(array[i], row)\n",
    "        \n",
    "        # the appended array will be one long vector\n",
    "        print(\"appended shape is {}\".format(appended.shape))\n",
    "        \n",
    "        # reshape the array with the original number of columns, extending the number of rows as necessary\n",
    "        appended = np.reshape(appended, (-1, array.shape[2]))\n",
    "        print(\"reshaped shape is {}\".format(appended.shape))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # update the new_array with this appended array\n",
    "        new_array[i] = appended\n",
    "       \n",
    "    # return the new_array\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function adds a single row to each channel, but I need to add an arbitrary number of rows  \n",
    "Let's see if I can modify the append section of the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "to create an update matrix, I needed to check the rules for broadcasting\n",
    "I don't know the method for converting a 1D array into a multi-dimensional one\n",
    "so I just multiplied it by an appropriately sized array of ones\n",
    "\"\"\"\n",
    "\n",
    "np.ones((2, 37)) * np.arange(1, 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes the same array and row inputs as the previous one, but it also takes a 'count' parameter which\n",
    "dictates how many times the row will be repeated at the end of the array, e.g. if count is 5, the array will be \n",
    "padded 5 times with the specified row\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def add_arbitrary_rows(array, row, count):\n",
    "    # the new empty array will have an arbitrary number of columns in each channel, dictated by the count parameter\n",
    "    new_array = np.zeros((array.shape[0], array.shape[1]+count, array.shape[2]))\n",
    "    \n",
    "    # if count is greater than 1, appending a matrix is easier than appending a row\n",
    "    update_matrix = np.ones((count, array.shape[2])) * row\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        print(\"new array shape is {}\".format(new_array[i].shape))\n",
    "        print(\"old array shape is {}\".format(array[i].shape))\n",
    "        print(\"update_matrix is {}\".format(update_matrix.shape))\n",
    "        \n",
    "        appended = np.append(array[i], update_matrix)\n",
    "        \n",
    "        print(\"appended shape is {}\".format(appended.shape))\n",
    "        \n",
    "        appended = np.reshape(appended, (-1, array.shape[2]))\n",
    "        print(\"reshaped shape is {}\".format(appended.shape))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # update the new_array with this appended array\n",
    "        new_array[i] = appended\n",
    "    \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now I can add an arbitrary number of rows to a channel in a matrix  \n",
    "  \n",
    "I think I can use this to process the Rinse_over_Run data  \n",
    "I'll loop over each process_id, and then use the add_arbitrary_rows function to add rows until it's equal to the size of the longest process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out - I should be able to isolate a single process_id from the train_converted data, and then add an arbitrary number of rows to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into an array\n",
    "tc_0_array = tc_0.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1425"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_0_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a row of zeros to be added\n",
    "zero_row = np.zeros((1, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c67fef4eb0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This won't work because the function assumes a 3D array, while the tc_0_array is only 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madd_arbitrary_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc_0_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-672d2816350c>\u001b[0m in \u001b[0;36madd_arbitrary_rows\u001b[0;34m(array, row, count)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_arbitrary_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# the new empty array will have an arbitrary number of columns in each channel, dictated by the count parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnew_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# if count is greater than 1, appending a matrix is easier than appending a row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# This won't work because the function assumes a 3D array, while the tc_0_array is only 2D\n",
    "add_arbitrary_rows(tc_0_array, zero_row, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a function that will add an arbitrary number of rows to a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rows_2d(array, row, count):\n",
    "    new_array = np.zeros((array.shape[0] + 1, array.shape[1]))\n",
    "    update_array = np.ones((count, array.shape[1])) * row\n",
    "    appended = np.append(array, update_array)\n",
    "    new_array = np.reshape(appended, (-1, array.shape[1]))\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_0_updated= add_rows_2d(tc_0_array, zero_row, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1427, 31)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tc_0_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now I can loop over all the arrays and update them to have the correct number of rows (np.max(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_0_maxLen = add_rows_2d(tc_0_array, zero_row, maxLen-tc_0_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11607, 31)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_0_maxLen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually Doing The Thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the train_converted Dataframe into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_array = train_converted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
